#!/usr/bin/env python3
"""
Local Database Analysis Tool
–õ–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É–¥–∞–ª–µ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
"""

import json
import os
import sys
from datetime import datetime
from typing import Any

try:
    import mysql.connector
    from mysql.connector import Error
except ImportError:
    print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω –º–æ–¥—É–ª—å mysql-connector-python")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –∫–æ–º–∞–Ω–¥–æ–π: pip install mysql-connector-python")
    sys.exit(1)


class LocalDatabaseAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞"""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª–µ–Ω–Ω–æ–π –ë–î"""
        self.config = {
            "host": "91.222.248.216",
            "port": 61315,
            "user": "khtrm_remote",
            "password": "KhTRM_2025!",
            "database": "saltdepoavt_",
            "charset": "utf8mb4",
            "use_unicode": True,
            "autocommit": True,
            "connect_timeout": 30,
            "buffered": True,
        }
        self.connection = None
        self.cursor = None

    def connect(self) -> bool:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª–µ–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print(f"üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ {self.config['host']}:{self.config['port']}...")
            self.connection = mysql.connector.connect(**self.config)
            self.cursor = self.connection.cursor(dictionary=True, buffered=True)
            print("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª–µ–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é —Å–µ—Ä–≤–µ—Ä–∞
            self.cursor.execute("SELECT VERSION() as version")
            version_info = self.cursor.fetchone()
            print(f"üìä –í–µ—Ä—Å–∏—è MySQL —Å–µ—Ä–≤–µ—Ä–∞: {version_info['version']}")

            return True
        except Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False

    def disconnect(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        if self.cursor:
            self.cursor.close()
        if self.connection:
            self.connection.close()
        print("üìù –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–æ")

    def get_all_tables(self) -> list[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü –≤ –ë–î"""
        try:
            self.cursor.execute("SHOW TABLES")
            tables = [
                row[f"Tables_in_{self.config['database']}"]
                for row in self.cursor.fetchall()
            ]
            return tables
        except Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ç–∞–±–ª–∏—Ü: {e}")
            return []

    def get_table_structure_detailed(self, table_name: str) -> dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            self.cursor.execute(f"DESCRIBE {table_name}")
            basic_structure = self.cursor.fetchall()

            # –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–æ–ª–±—Ü–∞—Ö
            self.cursor.execute(f"""
                SELECT
                    COLUMN_NAME,
                    DATA_TYPE,
                    IS_NULLABLE,
                    COLUMN_DEFAULT,
                    COLUMN_TYPE,
                    COLUMN_COMMENT,
                    ORDINAL_POSITION,
                    CHARACTER_MAXIMUM_LENGTH,
                    NUMERIC_PRECISION,
                    NUMERIC_SCALE
                FROM information_schema.COLUMNS
                WHERE TABLE_SCHEMA = '{self.config["database"]}'
                AND TABLE_NAME = '{table_name}'
                ORDER BY ORDINAL_POSITION
            """)
            detailed_structure = self.cursor.fetchall()

            # –ò–Ω–¥–µ–∫—Å—ã
            self.cursor.execute(f"SHOW INDEX FROM {table_name}")
            indexes = self.cursor.fetchall()

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            self.cursor.execute(f"SELECT COUNT(*) as count FROM {table_name}")
            count_result = self.cursor.fetchone()
            row_count = count_result["count"] if count_result else 0

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º
            self.cursor.execute(f"""
                SELECT
                    MIN(STR_TO_DATE(data_day, '%Y-%m-%d')) as min_date,
                    MAX(STR_TO_DATE(data_day, '%Y-%m-%d')) as max_date,
                    COUNT(DISTINCT data_day) as unique_dates
                FROM {table_name}
                WHERE data_day IS NOT NULL
            """)
            date_stats = self.cursor.fetchone()

            return {
                "basic_structure": basic_structure,
                "detailed_structure": detailed_structure,
                "indexes": indexes,
                "row_count": row_count,
                "date_statistics": date_stats,
            }

        except Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã {table_name}: {e}")
            return {}

    def analyze_field_relationships(self, table_name: str) -> dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –ø–æ–ª—è–º–∏"""
        try:
            # –ö–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–µ–π
            analysis_fields = [
                "marshrut",
                "vipusk",
                "smena",
                "tabvoditel",
                "fiovoditel",
                "tabconduktor",
                "fioconduktor",
                "pe‚Ññ",
                "putlist‚Ññ",
                "data_day",
            ]

            relationships = {}

            for field in analysis_fields:
                print(f"   üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ–ª–µ: {field}")

                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –∏—Ö —á–∞—Å—Ç–æ—Ç–∞
                try:
                    field_query = f"`{field}`" if "‚Ññ" in field else field

                    self.cursor.execute(f"""
                        SELECT {field_query} as value, COUNT(*) as count
                        FROM {table_name}
                        WHERE {field_query} IS NOT NULL
                        AND {field_query} != ''
                        GROUP BY {field_query}
                        ORDER BY count DESC, {field_query} ASC
                        LIMIT 50
                    """)
                    unique_values = self.cursor.fetchall()

                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—é
                    self.cursor.execute(f"""
                        SELECT
                            COUNT(DISTINCT {field_query}) as unique_count,
                            COUNT({field_query}) as non_null_count,
                            COUNT(*) as total_count
                        FROM {table_name}
                    """)
                    field_stats = self.cursor.fetchone()

                    relationships[field] = {
                        "unique_values": unique_values,
                        "statistics": field_stats,
                    }

                except Error as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª—è {field}: {e}")
                    relationships[field] = {"error": str(e)}

            return relationships

        except Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–µ–π –ø–æ–ª–µ–π: {e}")
            return {}

    def analyze_data_patterns(self, table_name: str) -> dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            patterns = {}

            # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–∞—Ç–∞–º
            print("   üìÖ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–∞—Ç–∞–º...")
            self.cursor.execute(f"""
                SELECT
                    data_day,
                    COUNT(*) as assignments_count,
                    COUNT(DISTINCT marshrut) as routes_count,
                    COUNT(DISTINCT smena) as shifts_count,
                    COUNT(DISTINCT tabvoditel) as drivers_count
                FROM {table_name}
                WHERE data_day >= '2025-07-01'
                GROUP BY data_day
                ORDER BY data_day DESC
                LIMIT 15
            """)
            date_patterns = self.cursor.fetchall()
            patterns["by_date"] = date_patterns

            # –ê–Ω–∞–ª–∏–∑ –ø–æ –º–∞—Ä—à—Ä—É—Ç–∞–º
            print("   üöå –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–∞—Ä—à—Ä—É—Ç–∞–º...")
            self.cursor.execute(f"""
                SELECT
                    marshrut,
                    COUNT(*) as total_assignments,
                    COUNT(DISTINCT data_day) as days_active,
                    COUNT(DISTINCT smena) as shifts_used,
                    COUNT(DISTINCT tabvoditel) as drivers_count
                FROM {table_name}
                WHERE data_day >= '2025-07-01'
                GROUP BY marshrut
                ORDER BY total_assignments DESC
                LIMIT 20
            """)
            route_patterns = self.cursor.fetchall()
            patterns["by_route"] = route_patterns

            # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–º–µ–Ω–∞–º
            print("   ‚è∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–º–µ–Ω–∞–º...")
            self.cursor.execute(f"""
                SELECT
                    smena,
                    COUNT(*) as total_assignments,
                    COUNT(DISTINCT marshrut) as routes_count,
                    COUNT(DISTINCT tabvoditel) as drivers_count,
                    AVG(TIME_TO_SEC(TIMEDIFF(tzah, tvih))/3600) as avg_work_hours
                FROM {table_name}
                WHERE data_day >= '2025-07-01'
                AND tvih IS NOT NULL
                AND tzah IS NOT NULL
                GROUP BY smena
                ORDER BY smena
            """)
            shift_patterns = self.cursor.fetchall()
            patterns["by_shift"] = shift_patterns

            return patterns

        except Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return {}

    def analyze_ms_access_structure(self) -> dict[str, Any]:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã MS Access"""
        try:
            print("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã MS Access...")

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            self.cursor.execute("""
                SELECT * FROM zanaradka
                WHERE data_day = '2025-07-07'
                ORDER BY marshrut, smena
                LIMIT 5
            """)
            sample_data = self.cursor.fetchall()

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –ø–æ–ª—è —Ç–∞–±–ª–∏—Ü—ã zanaradka
            self.cursor.execute("""
                SELECT COLUMN_NAME, DATA_TYPE, COLUMN_TYPE, COLUMN_COMMENT
                FROM information_schema.COLUMNS
                WHERE TABLE_SCHEMA = 'saltdepoavt_'
                AND TABLE_NAME = 'zanaradka'
                ORDER BY ORDINAL_POSITION
            """)
            all_fields = self.cursor.fetchall()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –ø–æ–ª—è —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∞–Ω–Ω—ã–µ
            fields_with_data = {}
            for field_info in all_fields:
                field_name = field_info["COLUMN_NAME"]
                field_query = f"`{field_name}`" if "‚Ññ" in field_name else field_name

                try:
                    self.cursor.execute(f"""
                        SELECT COUNT(*) as total,
                               COUNT({field_query}) as non_null,
                               COUNT(DISTINCT {field_query}) as unique_vals
                        FROM zanaradka
                        WHERE data_day >= '2025-07-01'
                    """)
                    field_stats = self.cursor.fetchone()
                    fields_with_data[field_name] = field_stats
                except Exception:
                    fields_with_data[field_name] = {"error": "Cannot analyze field"}

            return {
                "sample_data": sample_data,
                "all_fields": all_fields,
                "fields_with_data": fields_with_data,
            }

        except Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã MS Access: {e}")
            return {}

    def create_field_mapping_enhanced(self) -> dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã –ø–æ–ª–µ–π"""
        print("üó∫Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã –ø–æ–ª–µ–π...")

        # –ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ –ø–æ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã MS Access
        field_mapping = {
            # –û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
            "key": {
                "web_field": "id",
                "description": "–£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∑–∞–ø–∏—Å–∏",
                "type": "primary_key",
            },
            "data_day": {
                "web_field": "assignment_date",
                "description": "–î–∞—Ç–∞ –Ω–∞—Ä—è–¥–∞",
                "type": "date",
            },
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–∞—Ä—à—Ä—É—Ç–µ –∏ —Å–º–µ–Ω–µ
            "marshrut": {
                "web_field": "route_number",
                "description": "–ù–æ–º–µ—Ä –º–∞—Ä—à—Ä—É—Ç–∞",
                "type": "route_info",
            },
            "vipusk": {
                "web_field": "brigade",
                "description": "–ë—Ä–∏–≥–∞–¥–∞/–í—ã–ø—É—Å–∫",
                "type": "route_info",
            },
            "smena": {
                "web_field": "shift",
                "description": "–°–º–µ–Ω–∞",
                "type": "shift_info",
            },
            # –ü–µ—Ä—Å–æ–Ω–∞–ª
            "tabvoditel": {
                "web_field": "driver_tab_number",
                "description": "–¢–∞–±–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –≤–æ–¥–∏—Ç–µ–ª—è",
                "type": "personnel",
            },
            "fiovoditel": {
                "web_field": "driver_name",
                "description": "–§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è",
                "type": "personnel",
            },
            "tabconduktor": {
                "web_field": "conductor_tab_number",
                "description": "–¢–∞–±–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –∫–æ–Ω–¥—É–∫—Ç–æ—Ä–∞",
                "type": "personnel",
            },
            "fioconduktor": {
                "web_field": "conductor_name",
                "description": "–§–ò–û –∫–æ–Ω–¥—É–∫—Ç–æ—Ä–∞",
                "type": "personnel",
            },
            # –ü–æ–¥–≤–∏–∂–Ω–æ–π —Å–æ—Å—Ç–∞–≤
            "pe‚Ññ": {
                "web_field": "vehicle_number",
                "description": "–ù–æ–º–µ—Ä –ø–æ–¥–≤–∏–∂–Ω–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞",
                "type": "vehicle",
            },
            "putlist‚Ññ": {
                "web_field": "waybill_number",
                "description": "–ù–æ–º–µ—Ä –ø—É—Ç–µ–≤–æ–≥–æ –ª–∏—Å—Ç–∞",
                "type": "documents",
            },
            # –í—Ä–µ–º—è
            "tvih": {
                "web_field": "departure_time",
                "description": "–í—Ä–µ–º—è –≤—ã—Ö–æ–¥–∞",
                "type": "schedule",
            },
            "tzah": {
                "web_field": "arrival_time",
                "description": "–í—Ä–µ–º—è –∑–∞—Ö–æ–¥–∞",
                "type": "schedule",
            },
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            "ZaprAdr": {
                "web_field": "fuel_address",
                "description": "–ê–¥—Ä–µ—Å –∑–∞–ø—Ä–∞–≤–∫–∏",
                "type": "logistics",
            },
            "kpvih": {
                "web_field": "route_endpoint",
                "description": "–ö–æ–Ω–µ—á–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞",
                "type": "route_info",
            },
            "tipvipusk": {
                "web_field": "route_type",
                "description": "–¢–∏–ø –≤—ã–ø—É—Å–∫–∞",
                "type": "route_info",
            },
        }

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ–ª–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–∏–¥–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        view_configurations = {
            "simple": {
                "description": "–ü—Ä–æ—Å—Ç–æ–π –≤–∏–¥ - –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è",
                "fields": [
                    "route_number",
                    "shift",
                    "driver_name",
                    "vehicle_number",
                    "departure_time",
                    "arrival_time",
                    "status",
                ],
            },
            "extended": {
                "description": "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –≤–∏–¥ - –¥–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
                "fields": [
                    "route_number",
                    "brigade",
                    "shift",
                    "driver_tab_number",
                    "driver_name",
                    "conductor_name",
                    "vehicle_number",
                    "departure_time",
                    "arrival_time",
                    "waybill_number",
                    "fuel_address",
                    "route_endpoint",
                    "status",
                ],
            },
            "full_ms_access": {
                "description": "–ü–æ–ª–Ω—ã–π –≤–∏–¥ MS Access - –≤—Å–µ –ø–æ–ª—è",
                "fields": list(field_mapping.keys()),
            },
        }

        return {
            "field_mapping": field_mapping,
            "view_configurations": view_configurations,
            "total_fields": len(field_mapping),
        }

    def save_analysis_results(
        self, analysis_data: dict[str, Any], output_dir: str = "local_db_analysis"
    ):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ø–∞–ø–∫—É: {output_dir}")

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # JSON –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        with open(
            os.path.join(output_dir, f"full_analysis_{timestamp}.json"),
            "w",
            encoding="utf-8",
        ) as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2, default=str)

        # –ß–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
        with open(
            os.path.join(output_dir, f"analysis_report_{timestamp}.txt"),
            "w",
            encoding="utf-8",
        ) as f:
            f.write("=== –õ–û–ö–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –£–î–ê–õ–ï–ù–ù–û–ô –ë–ê–ó–´ –î–ê–ù–ù–´–• ===\n")
            f.write(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write(f"–°–µ—Ä–≤–µ—Ä: {self.config['host']}:{self.config['port']}\n")
            f.write(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.config['database']}\n\n")

            # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            f.write("=== –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø ===\n")
            f.write(f"–í—Å–µ–≥–æ —Ç–∞–±–ª–∏—Ü –≤ –ë–î: {len(analysis_data.get('all_tables', []))}\n")
            zanaradka_data = analysis_data.get("zanaradka_analysis", {})
            structure = zanaradka_data.get("structure", {})
            f.write(f"–ó–∞–ø–∏—Å–µ–π –≤ zanaradka: {structure.get('row_count', 0)}\n\n")

            # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã
            f.write("=== –°–¢–†–£–ö–¢–£–†–ê –¢–ê–ë–õ–ò–¶–´ ZANARADKA ===\n")
            if structure.get("detailed_structure"):
                for field in structure["detailed_structure"]:
                    f.write(f"{field['COLUMN_NAME']}: {field['COLUMN_TYPE']}")
                    if field["COLUMN_COMMENT"]:
                        f.write(f" -- {field['COLUMN_COMMENT']}")
                    f.write("\n")
                f.write("\n")

            # MS Access —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            ms_access = analysis_data.get("ms_access_analysis", {})
            if ms_access.get("all_fields"):
                f.write("=== –ê–ù–ê–õ–ò–ó –ü–û–õ–ï–ô MS ACCESS ===\n")
                for field in ms_access["all_fields"]:
                    field_name = field["COLUMN_NAME"]
                    data_info = ms_access.get("fields_with_data", {}).get(
                        field_name, {}
                    )
                    if not data_info.get("error"):
                        f.write(
                            f"{field_name}: {data_info.get('non_null', 0)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {data_info.get('total', 0)}\n"
                        )
                f.write("\n")

            # –ö–∞—Ä—Ç–∞ –ø–æ–ª–µ–π
            f.write("=== –ö–ê–†–¢–ê –ü–û–õ–ï–ô ===\n")
            field_mapping = analysis_data.get("enhanced_field_mapping", {}).get(
                "field_mapping", {}
            )
            for db_field, mapping_info in field_mapping.items():
                f.write(
                    f"{db_field} -> {mapping_info['web_field']} ({mapping_info['description']})\n"
                )
            f.write("\n")

            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            f.write("=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ===\n")
            recommendations = analysis_data.get("recommendations", [])
            for i, rec in enumerate(recommendations, 1):
                f.write(f"{i}. {rec}\n")

        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_dir}/")

    def run_full_analysis(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–π –ë–î"""
        print("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        print("=" * 70)

        if not self.connect():
            return False

        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
            print("üìã –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–∞–±–ª–∏—Ü...")
            all_tables = self.get_all_tables()
            print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(all_tables)}")

            # –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã zanaradka
            print("üìä –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã zanaradka...")
            zanaradka_structure = self.get_table_structure_detailed("zanaradka")

            # –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –ø–æ–ª–µ–π
            print("üîó –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –ø–æ–ª—è–º–∏...")
            field_relationships = self.analyze_field_relationships("zanaradka")

            # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            print("üìà –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")
            data_patterns = self.analyze_data_patterns("zanaradka")

            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ MS Access —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            print("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã MS Access...")
            ms_access_analysis = self.analyze_ms_access_structure()

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã –ø–æ–ª–µ–π
            enhanced_field_mapping = self.create_field_mapping_enhanced()

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            recommendations = [
                "‚úÖ –ü–æ–ª—è –ë–î —É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã (pe‚Ññ, putlist‚Ññ)",
                "‚úÖ Simple View —É–∂–µ —É–ª—É—á—à–µ–Ω",
                "üìù –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π –≤ Full View",
                "üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–¥–∏—Ä–æ–≤–∫—É —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤",
                "üìä –î–æ–±–∞–≤—å—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞–Ω–Ω—ã–º –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å",
                "üóÇÔ∏è –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É –ø–æ–ª–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
            ]

            # –°–±–æ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            full_analysis = {
                "timestamp": datetime.now().isoformat(),
                "database_info": {
                    "host": self.config["host"],
                    "database": self.config["database"],
                    "connection_status": "success",
                },
                "all_tables": all_tables,
                "zanaradka_analysis": {
                    "structure": zanaradka_structure,
                    "field_relationships": field_relationships,
                    "data_patterns": data_patterns,
                },
                "ms_access_analysis": ms_access_analysis,
                "enhanced_field_mapping": enhanced_field_mapping,
                "recommendations": recommendations,
            }

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self.save_analysis_results(full_analysis)

            print("=" * 70)
            print("‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print("üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ 'local_db_analysis'")
            print("üìä –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏:")
            print(f"   - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(all_tables)} —Ç–∞–±–ª–∏—Ü")
            print(
                f"   - –ù–∞–π–¥–µ–Ω–æ {len(enhanced_field_mapping['field_mapping'])} –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π"
            )
            print(
                f"   - –ó–∞–ø–∏—Å–µ–π –≤ zanaradka: {zanaradka_structure.get('row_count', 0)}"
            )
            print("   - –°–æ–∑–¥–∞–Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∫–∞—Ä—Ç–∞ –ø–æ–ª–µ–π")
            print("   - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é")

            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return False

        finally:
            self.disconnect()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç Local Database Analysis Tool")
    print("–õ–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É–¥–∞–ª–µ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞")
    print("=" * 70)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    print("üîß –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")

    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
    analyzer = LocalDatabaseAnalyzer()
    success = analyzer.run_full_analysis()

    if success:
        print(
            "\nüéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–ø–∫—É 'local_db_analysis' –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
        )
        print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –ò–∑—É—á–∏—Ç–µ analysis_report_*.txt")
        print("2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ full_analysis_*.json –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        print("3. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞")
    else:
        print("\n‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª–µ–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")

    return success


if __name__ == "__main__":
    main()
